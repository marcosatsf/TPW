{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21566461-a179-4df7-8621-803834840d6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T01:50:29.265571Z",
     "iopub.status.busy": "2025-08-14T01:50:29.262146Z",
     "iopub.status.idle": "2025-08-14T01:50:29.284097Z",
     "shell.execute_reply": "2025-08-14T01:50:29.280097Z",
     "shell.execute_reply.started": "2025-08-14T01:50:29.265255Z"
    }
   },
   "source": [
    "# Trace route\n",
    "\n",
    "This script is responsible to trace an optimized route!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616739f8-d03f-4abe-b895-d4aa1dd7c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a8586-716f-479a-9ed2-505e0361fc87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T05:08:49.156009Z",
     "start_time": "2025-08-22T05:08:49.110374Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf447ba-f45d-4867-a2c2-6760b2cdbaf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T05:11:59.610823Z",
     "start_time": "2025-08-22T05:11:59.415225Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.functions import explode, from_unixtime, col, to_date, sum, avg, udf, lit, date_trunc, when, max\n",
    "from pyspark.sql.types import DateType, TimestampType, StructType, StructField, IntegerType, FloatType, StringType\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta, date, tzinfo, timezone\n",
    "import psycopg2\n",
    "\n",
    "DB_URL = \"jdbc:postgresql://postgres:5432/themeparkwizard\"\n",
    "PROPERTIES_CUSTOM = {\"user\": os.environ['POSTGRES_USER'],\"password\": os.environ['POSTGRES_PASSWORD'], \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MetricPredict\") \\\n",
    "    .config(\"spark.jars\", \"jars/postgresql-42.7.7.jar\") \\\n",
    "    .config(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3859b4a2-74fc-425e-adc9-395692c81c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T05:12:00.500533Z",
     "start_time": "2025-08-22T05:12:00.440222Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "        host=\"postgres\",\n",
    "        port='5432',\n",
    "        database=\"themeparkwizard\",\n",
    "        user=os.environ['POSTGRES_USER'],\n",
    "        password=os.environ['POSTGRES_PASSWORD']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d8e45-c68c-46e0-be36-162efbba78de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T01:06:38.623163Z",
     "start_time": "2025-08-22T01:06:35.097424Z"
    }
   },
   "outputs": [],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"\"\"SELECT distinct id FROM themeparkwizard.dim_park_entity\"\"\")\n",
    "    park_id_list = cur.fetchall()\n",
    "    predicted_data = {}\n",
    "    for park_id in park_id_list:\n",
    "        cur.execute(f\"\"\"\n",
    "    with number_row as (\n",
    "        select\n",
    "            entity_id,\n",
    "            name,\n",
    "            entity_name,\n",
    "            latitude,\n",
    "            longitude,\n",
    "            wait_time,\n",
    "            extracted_at_time,\n",
    "            rating,\n",
    "            row_number() over (partition by entity_id order by extracted_at_time) as rn\n",
    "        from themeparkwizard.predictions_table pt\n",
    "        left join themeparkwizard.dim_park_entity dpe using(entity_id)\n",
    "        where was_predicted = 1 and dpe.id = '{park_id[0]}'\n",
    "    ),\n",
    "    avg_by_entity AS (\n",
    "        SELECT\n",
    "            entity_id,\n",
    "            AVG(avg_standby_waittime) as alltime_avg_waittime\n",
    "        FROM themeparkwizard.agg_avg_time\n",
    "        GROUP BY 1\n",
    "    ),\n",
    "    first_group as (\n",
    "        select extracted_at_time,\n",
    "               wait_time,\n",
    "               entity_name,\n",
    "               entity_id,\n",
    "               latitude,\n",
    "               longitude,\n",
    "               name,\n",
    "               rating,\n",
    "               alltime_avg_waittime\n",
    "        from number_row\n",
    "                 left join avg_by_entity\n",
    "                           using (entity_id)\n",
    "        where rn <> 1\n",
    "        order by extracted_at_time, entity_id\n",
    "    )\n",
    "    select\n",
    "        extracted_at_time,\n",
    "        a.entity_id as src_node,\n",
    "        b.entity_id as dst_node,\n",
    "        SQRT(POWER((b.latitude - a.latitude)*111, 2) + POWER((b.longitude - a.longitude)*111, 2)) AS euclidean_distance,\n",
    "        b.wait_time,\n",
    "        b.alltime_avg_waittime,\n",
    "        b.rating\n",
    "    from first_group a\n",
    "    full join first_group b\n",
    "    using(extracted_at_time, name)\n",
    "    order by 1,2,3\n",
    "        \"\"\")\n",
    "    # extracted_at_time datetime 0\n",
    "    # source_node (A) string 1\n",
    "    # destination_node (B) string 2\n",
    "    # euclidean distance (from A to B) float 3\n",
    "    # wait time (queue B) float 4\n",
    "    # all time wait time (queue B) float 5\n",
    "    # rating (B) float 6\n",
    "        predicted_data[park_id[0]] = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d802c4fadfe571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T01:06:38.732397Z",
     "start_time": "2025-08-22T01:06:38.720299Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(predicted_data)\n",
    "for k,v in predicted_data.items():\n",
    "    print(k, len(v), sep='->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4279fb6928396bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T02:32:56.879592Z",
     "start_time": "2025-08-22T02:32:56.746992Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_weight(rating: float, queue_i: float, dist: float, queue_avg: float):\n",
    "    # function = 4**(10/r)*q*(d+1)/AVG(q)\n",
    "    value = 4**(10/rating)*(queue_i*(dist+1))/queue_avg\n",
    "    return value, round(queue_i + 10, -1)\n",
    "\n",
    "def fill_time_matrix(matrix, len_a, bad_node):\n",
    "    new_matrix = []\n",
    "    for i in range(len_a):\n",
    "        new_matrix.append([None]*len_a)\n",
    "        for j in range(len_a):\n",
    "            try:\n",
    "                new_matrix[i][j] = matrix[i][j]\n",
    "            except IndexError:\n",
    "                new_matrix[i][j] = bad_node\n",
    "    return new_matrix\n",
    "\n",
    "def create_map_attr(query_result):\n",
    "    map_attr = defaultdict(dict)\n",
    "\n",
    "    for park_id in query_result:\n",
    "        end_creation = False\n",
    "        dest_node = ''\n",
    "        attr_idx = 0\n",
    "        for row in query_result[park_id]:\n",
    "        # Fill map_attractions with a symbol\n",
    "            for i in range(1,3):\n",
    "                if not row[i] in [k for k, _ in map_attr[park_id].values()]:\n",
    "                    while True:\n",
    "                        key_map = ''.join(random.choices(string.ascii_uppercase, k=2))\n",
    "                        if not map_attr[park_id].get(key_map):\n",
    "                            break\n",
    "                    map_attr[park_id][key_map] = (row[i],attr_idx)\n",
    "                    attr_idx += 1\n",
    "            if row[1] != row[2] and not end_creation:\n",
    "                dest_node = row[2]\n",
    "                end_creation = True\n",
    "            if row[1] == dest_node:\n",
    "                break\n",
    "    return map_attr\n",
    "\n",
    "def create_cost_by_time(query_result, len_attr):\n",
    "    INF_MAX = math.inf\n",
    "    bad_node = (INF_MAX, 60*24*10)\n",
    "    cost_time = defaultdict(dict)\n",
    "    last_node = ''\n",
    "\n",
    "    for park_id in query_result:\n",
    "        tmp_range = []\n",
    "        for row in query_result[park_id]:\n",
    "            # Next row on matrix!\n",
    "            if last_node != row[1]:\n",
    "                if last_node != '':\n",
    "                    tmp_range.append(inner_tmp_range.copy())\n",
    "                last_node = row[1]\n",
    "                inner_tmp_range = []\n",
    "            # Checkout date matrix\n",
    "            if not cost_time[park_id].get(row[0]):\n",
    "                if tmp_range:\n",
    "                    cost_time[park_id][row[0]] = fill_time_matrix(tmp_range, len_attr[park_id], bad_node)\n",
    "                tmp_range = []\n",
    "            # Calculate cost\n",
    "            if row[1] == row[2]:\n",
    "                inner_tmp_range.append(bad_node)\n",
    "            else:\n",
    "                inner_tmp_range.append(calculate_weight(row[6],row[4],row[3],row[5]))\n",
    "    return cost_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a82da-37b2-4b0f-be7d-b78e91e3b1c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T02:32:59.612802Z",
     "start_time": "2025-08-22T02:32:57.654205Z"
    }
   },
   "outputs": [],
   "source": [
    "map_attractions = create_map_attr(predicted_data)\n",
    "len_attractions = {k:len(map_attractions[k]) for k in map_attractions}\n",
    "map_by_time = create_cost_by_time(predicted_data, len_attractions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf6d89-aea7-4e1a-aab7-312f4f20d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, e in enumerate(map_by_time['1c84a229-8862-4648-9c71-378ddd2c7693'].keys()):\n",
    "    print('*'*60)\n",
    "    print(f\"Matrix of weights and distances for the given time: {e} [datetime]\")\n",
    "    print('[')\n",
    "    for k in map_by_time['1c84a229-8862-4648-9c71-378ddd2c7693'][e]:\n",
    "        print(k)\n",
    "    print(']')\n",
    "    if idx == 2:\n",
    "        print('.', '.', '.', sep='\\n')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e1731-634f-431c-8247-8b1b2ca4be3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T02:33:02.278443Z",
     "start_time": "2025-08-22T02:33:02.210302Z"
    }
   },
   "outputs": [],
   "source": [
    "map_attractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15592f7b42ec68c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T05:11:13.570050Z",
     "start_time": "2025-08-22T05:11:13.412005Z"
    }
   },
   "outputs": [],
   "source": [
    "import genetic_algorithm_tour as gat\n",
    "\n",
    "POPULATION_SIZE = 10\n",
    "NUM_GENERATIONS = 10\n",
    "CROSSOVER_RATE = 0.8\n",
    "MUTATION_RATE = 0.01\n",
    "\n",
    "dict_results = defaultdict(dict)\n",
    "for park_id in map_attractions.keys():\n",
    "    print('*'*10,f'Procreating population from park : {park_id}','*'*10)\n",
    "    dict_results[park_id]['best_gene'], dict_results[park_id]['best_cost'], dict_results[park_id]['initial_time'] = gat.genetic_algorithm(\n",
    "        pop_size=POPULATION_SIZE*math.ceil(len(predicted_data[park_id])/5000)+10,\n",
    "        num_generations=NUM_GENERATIONS*math.ceil(len(predicted_data[park_id])/5000),\n",
    "        allele_map=map_attractions[park_id],\n",
    "        predicted_map=map_by_time[park_id],\n",
    "        crossover_rate=CROSSOVER_RATE,\n",
    "        mutation_rate=MUTATION_RATE\n",
    "    )\n",
    "    print('*'*10,f'End population from park : {park_id}','*'*10)\n",
    "print('What an end of an Era...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb910f26-e368-444e-9c98-a1efdf6bb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = []\n",
    "\n",
    "for park_id in dict_results:\n",
    "    initial_time = min([t for t in map_by_time[park_id].keys()])\n",
    "    print(f'PARK {park_id} ROUTE OSCAR')\n",
    "    print('...AND THE WINNER OF BEST GENE IS:')\n",
    "    print(dict_results[park_id]['best_gene'])\n",
    "    print('...Starring:')\n",
    "    last = None\n",
    "\n",
    "    for node in dict_results[park_id]['best_gene']:\n",
    "        if not last:\n",
    "            result_set.append((park_id, map_attractions[park_id][node][0], initial_time, 0.0))\n",
    "            print(f'Go to {map_attractions[park_id][node][0]} at {initial_time}')\n",
    "            last = node\n",
    "            continue\n",
    "        weight_result, time_passed = map_by_time[park_id][initial_time][map_attractions[park_id][last][1]][map_attractions[park_id][node][1]]\n",
    "        initial_time += timedelta(minutes=time_passed)\n",
    "        result_set.append((park_id, map_attractions[park_id][node][0], initial_time, time_passed))\n",
    "        print(f'Go to {map_attractions[park_id][node][0]} at {initial_time}')\n",
    "        last = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74376b4-aeb3-427c-87be-4c4f1412f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_URL = \"jdbc:postgresql://postgres:5432/themeparkwizard\"\n",
    "PROPERTIES_CUSTOM = {\"user\": os.environ['POSTGRES_USER'],\"password\": os.environ['POSTGRES_PASSWORD'], \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"park_id\", StringType(), False),\n",
    "    StructField(\"entity_id\", StringType(), False),\n",
    "    StructField(\"datetime_point\", TimestampType(), False),\n",
    "    StructField(\"waiting_time\", FloatType(), False)\n",
    "])\n",
    "spark.createDataFrame(result_set, schema)\\\n",
    "    .orderBy('park_id', 'datetime_point')\\\n",
    "    .write.jdbc(url=DB_URL, table=f\"themeparkwizard.best_route\", mode='overwrite', properties=PROPERTIES_CUSTOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f88f47-ee26-4141-a0ee-e76e169a7d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ebea0-a717-4dfc-b7d0-36a73e46aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd0bbf-9b91-438c-9c88-afe9603f73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4fdfeb-9dc6-4c86-8bfc-9705632c1b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
